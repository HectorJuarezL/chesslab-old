{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chesslab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chesslab.utils import load_pkl\n",
    "from chesslab.training_tf import fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=1\n",
    "lr = 0.1\n",
    "epochs=5\n",
    "batch_size = 128\n",
    "test_percent=0.1\n",
    "\n",
    "path = 'D:/database/ccrl/'\n",
    "name_data='ccrl_states_elo2.pkl'\n",
    "name_labels='ccrl_results_elo2.pkl'\n",
    "save_name='./tmp/tf_elo.0'\n",
    "\n",
    "optim = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download=False\n",
    "if download:\n",
    "    from chesslab.utils import download_7z\n",
    "    path='./'\n",
    "    file_id = '1MFHFz_rxNziYSeN-9ruwnRiYskd0_9ss'\n",
    "    download_7z(file_id,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoding_1={\n",
    "    '.':np.array([ 0, 0, 0],dtype=np.float),\n",
    "    'p':np.array([ 0, 0, 1],dtype=np.float),\n",
    "    'P':np.array([ 0, 0,-1],dtype=np.float),\n",
    "    'b':np.array([ 0, 1, 0],dtype=np.float),\n",
    "    'B':np.array([ 0,-1, 0],dtype=np.float),\n",
    "    'n':np.array([ 1, 0, 0],dtype=np.float),\n",
    "    'N':np.array([-1, 0, 0],dtype=np.float),\n",
    "    'r':np.array([ 0, 1, 1],dtype=np.float),\n",
    "    'R':np.array([ 0,-1,-1],dtype=np.float),\n",
    "    'q':np.array([ 1, 0, 1],dtype=np.float),\n",
    "    'Q':np.array([-1, 0,-1],dtype=np.float),\n",
    "    'k':np.array([ 1, 1, 0],dtype=np.float),\n",
    "    'K':np.array([-1,-1, 0],dtype=np.float)\n",
    "}\n",
    "\n",
    "encoding_2={\n",
    "    '.':np.array([0,0,0,0],dtype=np.float),\n",
    "    'p':np.array([1,0,0,0],dtype=np.float),\n",
    "    'P':np.array([0,0,0,1],dtype=np.float),\n",
    "    'b':np.array([0,1,0,0],dtype=np.float),\n",
    "    'B':np.array([0,0,1,0],dtype=np.float),\n",
    "    'n':np.array([1,1,0,0],dtype=np.float),\n",
    "    'N':np.array([0,0,1,1],dtype=np.float),\n",
    "    'r':np.array([1,0,1,0],dtype=np.float),\n",
    "    'R':np.array([0,1,0,1],dtype=np.float),\n",
    "    'q':np.array([1,0,0,1],dtype=np.float),\n",
    "    'Q':np.array([0,1,1,0],dtype=np.float),\n",
    "    'k':np.array([1,1,1,0],dtype=np.float),\n",
    "    'K':np.array([0,1,1,1],dtype=np.float)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1():\n",
    "\n",
    "    def __init__(self,\n",
    "                   n_classes=2):\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "        self.hw=[]\n",
    "        self.hb=[]\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(7,7,3,32)),name=\"hl1weigths\",dtype=\"float32\") )\n",
    "        self.hb.append( tf.Variable(np.zeros(32),name=\"hl1bias\",dtype=\"float32\") )\n",
    "        #8x8x32\n",
    "        self.hw.append( tf.Variable(initializer(shape=(5,5,32,64)),name=\"hl2weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(64),name=\"hl2bias\",dtype=\"float32\"))\n",
    "        #8x8x64\n",
    "        self.hw.append( tf.Variable(initializer(shape=(3,3,64,128)),name=\"hl3weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(128),name=\"hl3bias\",dtype=\"float32\"))\n",
    "        #8x8x128\n",
    "        self.hw.append( tf.Variable(initializer(shape=(8*8*128,256)),name=\"hl4weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(256),name=\"hl4bias\",dtype=\"float32\"))\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(256, n_classes)),name=\"outweigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(n_classes),name=\"outbias\",dtype=\"float32\"))\n",
    "\n",
    "        self.trainable_variables = []\n",
    "        for i in range(len(self.hw)):\n",
    "            self.trainable_variables.append(self.hw[i])    \n",
    "            self.trainable_variables.append(self.hb[i])\n",
    "\n",
    "    def __call__(self,x): \n",
    "\n",
    "        # Declarando la arquitectura\n",
    "        out = tf.cast(x, tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 8, 8, 3])\n",
    "\n",
    "        layer=0\n",
    "        out = tf.add(out, 1e-8)\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*32\n",
    "        layer+=1\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*64\n",
    "        layer+=1  \n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*128\n",
    "        layer+=1\n",
    "        out =  tf.reshape(out,[-1, 8*8*128])\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "\n",
    "        layer+=1\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Model_2():\n",
    "\n",
    "    def __init__(self,\n",
    "                   n_classes=2):\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "        self.hw=[]\n",
    "        self.hb=[]\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(7,7,4,32)),name=\"hl1weigths\",dtype=\"float32\") )\n",
    "        self.hb.append( tf.Variable(np.zeros(32),name=\"hl1bias\",dtype=\"float32\") )\n",
    "        #8x8x32\n",
    "        self.hw.append( tf.Variable(initializer(shape=(5,5,32,64)),name=\"hl2weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(64),name=\"hl2bias\",dtype=\"float32\"))\n",
    "        #8x8x64\n",
    "        self.hw.append( tf.Variable(initializer(shape=(3,3,64,128)),name=\"hl3weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(128),name=\"hl3bias\",dtype=\"float32\"))\n",
    "        #8x8x128\n",
    "        self.hw.append( tf.Variable(initializer(shape=(8*8*128,256)),name=\"hl4weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(256),name=\"hl4bias\",dtype=\"float32\"))\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(256, n_classes)),name=\"outweigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(n_classes),name=\"outbias\",dtype=\"float32\"))\n",
    "\n",
    "        self.trainable_variables = []\n",
    "        for i in range(len(self.hw)):\n",
    "            self.trainable_variables.append(self.hw[i])    \n",
    "            self.trainable_variables.append(self.hb[i])\n",
    "\n",
    "    def __call__(self,x): \n",
    "\n",
    "        out = tf.cast(x, tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 8, 8, 4])\n",
    "\n",
    "        layer=0\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "              #8*8*32\n",
    "        layer+=1\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "              #8*8*64\n",
    "        layer+=1  \n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*128\n",
    "        layer+=1\n",
    "        out =  tf.reshape(out,[-1, 8*8*128])\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "\n",
    "        layer+=1\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 64)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "x_data = load_pkl(path+name_data)[:100000]\n",
    "y_data = load_pkl(path+name_labels)[:100000,1] #Nota: las etiquetas deben de ser enteros, no onehot\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size = test_percent, random_state = 0, shuffle = True)\n",
    "\n",
    "del x_data\n",
    "del y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if example==1:\n",
    "    model = Model_1()\n",
    "    encoding=encoding_1\n",
    "else:\n",
    "    model = Model_2()\n",
    "    encoding=encoding_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 14:42:20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 01/05 | time: 8s = 0.1m | train loss: 0.6321 | train acc: 0.6424 | test loss: 0.6115 | test acc: 0.6677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 02/05 | time: 5s = 0.1m | train loss: 0.6079 | train acc: 0.6611 | test loss: 0.5878 | test acc: 0.6790"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 03/05 | time: 5s = 0.1m | train loss: 0.5869 | train acc: 0.6787 | test loss: 0.5786 | test acc: 0.6874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 04/05 | time: 5s = 0.1m | train loss: 0.5655 | train acc: 0.6956 | test loss: 0.5707 | test acc: 0.6996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 05/05 | time: 5s = 0.1m | train loss: 0.5427 | train acc: 0.7128 | test loss: 0.5418 | test acc: 0.7221"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitting(epochs=epochs,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        model=model,\n",
    "        optimizer=optim,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        loss_fn=loss_fn,\n",
    "        save_name=save_name,\n",
    "        encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 14:42:49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 02/02 | time: 5s = 0.1m | train loss: 0.6069 | train acc: 0.6648 | test loss: 0.6041 | test acc: 0.6690"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitting(epochs=1,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        model= model, \n",
    "        load_name='tmp/tf_elo.0.1.h5',\n",
    "        save_name=save_name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
