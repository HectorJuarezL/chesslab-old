{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chesslab_.utils import params,load_pkl\n",
    "from chesslab_.training_tf import fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=1\n",
    "lr = 0.1\n",
    "epochs=5\n",
    "batch_size = 128\n",
    "test_percent=0.1\n",
    "\n",
    "path = 'D:/database/ccrl/'\n",
    "name_data='ccrl_states_elo2.pkl'\n",
    "name_labels='ccrl_results_elo2.pkl'\n",
    "save_name='./tmp/tf_elo.0'\n",
    "\n",
    "optim = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from chesslab_.utils import download_7z\n",
    "\n",
    "#https://drive.google.com/open?id=1VcBSGF8hporXnVDm8iCwc3BrDpFTBG4W\n",
    "file_id = '1VcBSGF8hporXnVDm8iCwc3BrDpFTBG4W'\n",
    "download_7z(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoding_1={\n",
    "    '.':np.array([ 0, 0, 0],dtype=np.float),\n",
    "    'p':np.array([ 0, 0, 1],dtype=np.float),\n",
    "    'P':np.array([ 0, 0,-1],dtype=np.float),\n",
    "    'b':np.array([ 0, 1, 0],dtype=np.float),\n",
    "    'B':np.array([ 0,-1, 0],dtype=np.float),\n",
    "    'n':np.array([ 1, 0, 0],dtype=np.float),\n",
    "    'N':np.array([-1, 0, 0],dtype=np.float),\n",
    "    'r':np.array([ 0, 1, 1],dtype=np.float),\n",
    "    'R':np.array([ 0,-1,-1],dtype=np.float),\n",
    "    'q':np.array([ 1, 0, 1],dtype=np.float),\n",
    "    'Q':np.array([-1, 0,-1],dtype=np.float),\n",
    "    'k':np.array([ 1, 1, 0],dtype=np.float),\n",
    "    'K':np.array([-1,-1, 0],dtype=np.float)\n",
    "}\n",
    "\n",
    "encoding_2={\n",
    "    '.':np.array([0,0,0,0],dtype=np.float),\n",
    "    'p':np.array([1,0,0,0],dtype=np.float),\n",
    "    'P':np.array([0,0,0,1],dtype=np.float),\n",
    "    'b':np.array([0,1,0,0],dtype=np.float),\n",
    "    'B':np.array([0,0,1,0],dtype=np.float),\n",
    "    'n':np.array([1,1,0,0],dtype=np.float),\n",
    "    'N':np.array([0,0,1,1],dtype=np.float),\n",
    "    'r':np.array([1,0,1,0],dtype=np.float),\n",
    "    'R':np.array([0,1,0,1],dtype=np.float),\n",
    "    'q':np.array([1,0,0,1],dtype=np.float),\n",
    "    'Q':np.array([0,1,1,0],dtype=np.float),\n",
    "    'k':np.array([1,1,1,0],dtype=np.float),\n",
    "    'K':np.array([0,1,1,1],dtype=np.float)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1():\n",
    "\n",
    "    def __init__(self,\n",
    "                   n_classes=2):\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "        self.hw=[]\n",
    "        self.hb=[]\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(7,7,3,32)),name=\"hl1weigths\",dtype=\"float32\") )\n",
    "        self.hb.append( tf.Variable(np.zeros(32),name=\"hl1bias\",dtype=\"float32\") )\n",
    "        #8x8x32\n",
    "        self.hw.append( tf.Variable(initializer(shape=(5,5,32,64)),name=\"hl2weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(64),name=\"hl2bias\",dtype=\"float32\"))\n",
    "        #8x8x64\n",
    "        self.hw.append( tf.Variable(initializer(shape=(3,3,64,128)),name=\"hl3weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(128),name=\"hl3bias\",dtype=\"float32\"))\n",
    "        #8x8x128\n",
    "        self.hw.append( tf.Variable(initializer(shape=(8*8*128,256)),name=\"hl4weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(256),name=\"hl4bias\",dtype=\"float32\"))\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(256, n_classes)),name=\"outweigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(n_classes),name=\"outbias\",dtype=\"float32\"))\n",
    "\n",
    "        self.trainable_variables = []\n",
    "        for i in range(len(self.hw)):\n",
    "            self.trainable_variables.append(self.hw[i])    \n",
    "            self.trainable_variables.append(self.hb[i])\n",
    "\n",
    "    def __call__(self,x): \n",
    "\n",
    "        # Declarando la arquitectura\n",
    "        out = tf.cast(x, tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 8, 8, 3])\n",
    "\n",
    "        layer=0\n",
    "        out = tf.add(out, 1e-8)\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*32\n",
    "        layer+=1\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*64\n",
    "        layer+=1  \n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*128\n",
    "        layer+=1\n",
    "        out =  tf.reshape(out,[-1, 8*8*128])\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "\n",
    "        layer+=1\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Model_2():\n",
    "\n",
    "    def __init__(self,\n",
    "                   n_classes=2):\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "        self.hw=[]\n",
    "        self.hb=[]\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(7,7,4,32)),name=\"hl1weigths\",dtype=\"float32\") )\n",
    "        self.hb.append( tf.Variable(np.zeros(32),name=\"hl1bias\",dtype=\"float32\") )\n",
    "        #8x8x32\n",
    "        self.hw.append( tf.Variable(initializer(shape=(5,5,32,64)),name=\"hl2weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(64),name=\"hl2bias\",dtype=\"float32\"))\n",
    "        #8x8x64\n",
    "        self.hw.append( tf.Variable(initializer(shape=(3,3,64,128)),name=\"hl3weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(128),name=\"hl3bias\",dtype=\"float32\"))\n",
    "        #8x8x128\n",
    "        self.hw.append( tf.Variable(initializer(shape=(8*8*128,256)),name=\"hl4weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(256),name=\"hl4bias\",dtype=\"float32\"))\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(256, n_classes)),name=\"outweigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(n_classes),name=\"outbias\",dtype=\"float32\"))\n",
    "\n",
    "        self.trainable_variables = []\n",
    "        for i in range(len(self.hw)):\n",
    "            self.trainable_variables.append(self.hw[i])    \n",
    "            self.trainable_variables.append(self.hb[i])\n",
    "\n",
    "    def __call__(self,x): \n",
    "\n",
    "        out = tf.cast(x, tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 8, 8, 4])\n",
    "\n",
    "        layer=0\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "              #8*8*32\n",
    "        layer+=1\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "              #8*8*64\n",
    "        layer+=1  \n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*128\n",
    "        layer+=1\n",
    "        out =  tf.reshape(out,[-1, 8*8*128])\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "\n",
    "        layer+=1\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6291280, 64)\n",
      "(6291280,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "x_data = load_pkl(path+name_data)\n",
    "y_data = load_pkl(path+name_labels)[:,1] #Nota: las etiquetas deben de ser enteros, no onehot\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size = test_percent, random_state = 0, shuffle = True)\n",
    "\n",
    "del x_data\n",
    "del y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if example==1:\n",
    "    model = Model_1()\n",
    "    encoding=encoding_1\n",
    "else:\n",
    "    model = Model_2()\n",
    "    encoding=encoding_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-23 22:14:28\n",
      "Epoch: 01/05 | time: 240s = 4.0m | train loss: 0.5428 | train acc: 0.7101 | test loss: 0.5434 | test acc: 0.7144\n",
      "Epoch: 02/05 | time: 239s = 4.0m | train loss: 0.4987 | train acc: 0.7424 | test loss: 0.4758 | test acc: 0.7590\n",
      "Epoch: 03/05 | time: 253s = 4.2m | train loss: 0.4708 | train acc: 0.7611 | test loss: 0.4605 | test acc: 0.7649\n",
      "Epoch: 04/05 | time: 240s = 4.0m | train loss: 0.4512 | train acc: 0.7746 | test loss: 0.4709 | test acc: 0.7540\n",
      "Epoch: 05/05 | time: 240s = 4.0m | train loss: 0.4342 | train acc: 0.7865 | test loss: 0.4600 | test acc: 0.7747\n"
     ]
    }
   ],
   "source": [
    "fitting(epochs=epochs,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        model=model,\n",
    "        optimizer=optim,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        loss_fn=loss_fn,\n",
    "        save_name=save_name,\n",
    "        encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-23 22:34:41\n",
      "Epoch: 02/02 | time: 240s = 4.0m | train loss: 0.4991 | train acc: 0.7419 | test loss: 0.5097 | test acc: 0.7390\n"
     ]
    }
   ],
   "source": [
    "fitting(epochs=1,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        model= model, \n",
    "        load_name='tmp/tf_elo.0.1.h5',\n",
    "        save_name=save_name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
