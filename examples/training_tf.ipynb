{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chesslab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chesslab.utils import load_pkl\n",
    "from chesslab.training_tf import fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=1\n",
    "lr = 0.1\n",
    "epochs=30\n",
    "batch_size = 128\n",
    "test_percent=0.1\n",
    "\n",
    "path = 'D:/database/ccrl/'\n",
    "name_data='ccrl_states_elo2.pkl'\n",
    "name_labels='ccrl_results_elo2.pkl'\n",
    "save_name='./tmp/tf_weights.0'\n",
    "\n",
    "optim = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download=False\n",
    "if download:\n",
    "    from chesslab.utils import download_7z\n",
    "    path='./'\n",
    "    file_id = '1MFHFz_rxNziYSeN-9ruwnRiYskd0_9ss'\n",
    "    download_7z(file_id,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_1={\n",
    "    '.':np.array([ 0, 0, 0],dtype=np.float32),\n",
    "    'p':np.array([ 0, 0, 1],dtype=np.float32),\n",
    "    'P':np.array([ 0, 0,-1],dtype=np.float32),\n",
    "    'b':np.array([ 0, 1, 0],dtype=np.float32),\n",
    "    'B':np.array([ 0,-1, 0],dtype=np.float32),\n",
    "    'n':np.array([ 1, 0, 0],dtype=np.float32),\n",
    "    'N':np.array([-1, 0, 0],dtype=np.float32),\n",
    "    'r':np.array([ 0, 1, 1],dtype=np.float32),\n",
    "    'R':np.array([ 0,-1,-1],dtype=np.float32),\n",
    "    'q':np.array([ 1, 0, 1],dtype=np.float32),\n",
    "    'Q':np.array([-1, 0,-1],dtype=np.float32),\n",
    "    'k':np.array([ 1, 1, 0],dtype=np.float32),\n",
    "    'K':np.array([-1,-1, 0],dtype=np.float32)\n",
    "}\n",
    "\n",
    "encoding_2={\n",
    "    '.':np.array([0,0,0,0],dtype=np.float32),\n",
    "    'p':np.array([1,0,0,0],dtype=np.float32),\n",
    "    'P':np.array([0,0,0,1],dtype=np.float32),\n",
    "    'b':np.array([0,1,0,0],dtype=np.float32),\n",
    "    'B':np.array([0,0,1,0],dtype=np.float32),\n",
    "    'n':np.array([1,1,0,0],dtype=np.float32),\n",
    "    'N':np.array([0,0,1,1],dtype=np.float32),\n",
    "    'r':np.array([1,0,1,0],dtype=np.float32),\n",
    "    'R':np.array([0,1,0,1],dtype=np.float32),\n",
    "    'q':np.array([1,0,0,1],dtype=np.float32),\n",
    "    'Q':np.array([0,1,1,0],dtype=np.float32),\n",
    "    'k':np.array([1,1,1,0],dtype=np.float32),\n",
    "    'K':np.array([0,1,1,1],dtype=np.float32)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1():\n",
    "\n",
    "    def __init__(self,\n",
    "                   n_classes=2):\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "        self.hw=[]\n",
    "        self.hb=[]\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(7,7,3,32),dtype=np.float32),name=\"hl1weigths\",dtype=\"float32\") )\n",
    "        self.hb.append( tf.Variable(np.zeros(32,dtype=np.float32),name=\"hl1bias\",dtype=\"float32\") )\n",
    "        #8x8x32\n",
    "        self.hw.append( tf.Variable(initializer(shape=(5,5,32,64),dtype=np.float32),name=\"hl2weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(64,dtype=np.float32),name=\"hl2bias\",dtype=\"float32\"))\n",
    "        #8x8x64\n",
    "        self.hw.append( tf.Variable(initializer(shape=(3,3,64,128),dtype=np.float32),name=\"hl3weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(128,dtype=np.float32),name=\"hl3bias\",dtype=\"float32\"))\n",
    "        #8x8x128\n",
    "        self.hw.append( tf.Variable(initializer(shape=(8*8*128,256),dtype=np.float32),name=\"hl4weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(256,dtype=np.float32),name=\"hl4bias\",dtype=\"float32\"))\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(256, n_classes),dtype=np.float32),name=\"outweigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(n_classes,dtype=np.float32),name=\"outbias\",dtype=\"float32\"))\n",
    "\n",
    "        self.trainable_variables = []\n",
    "        for i in range(len(self.hw)):\n",
    "            self.trainable_variables.append(self.hw[i])    \n",
    "            self.trainable_variables.append(self.hb[i])\n",
    "\n",
    "    def __call__(self,x): \n",
    "\n",
    "        # Declarando la arquitectura\n",
    "        out = tf.cast(x, tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 8, 8, 3])\n",
    "\n",
    "        layer=0\n",
    "        out = tf.add(out, 1e-8)\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*32\n",
    "        layer+=1\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*64\n",
    "        layer+=1  \n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*128\n",
    "        layer+=1\n",
    "        out =  tf.reshape(out,[-1, 8*8*128])\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "\n",
    "        layer+=1\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Model_2():\n",
    "\n",
    "    def __init__(self,\n",
    "                   n_classes=2):\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "        self.hw=[]\n",
    "        self.hb=[]\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(7,7,4,32),dtype=np.float32),name=\"hl1weigths\",dtype=\"float32\") )\n",
    "        self.hb.append( tf.Variable(np.zeros(32,dtype=np.float32),name=\"hl1bias\",dtype=\"float32\") )\n",
    "        #8x8x32\n",
    "        self.hw.append( tf.Variable(initializer(shape=(5,5,32,64),dtype=np.float32),name=\"hl2weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(64,dtype=np.float32),name=\"hl2bias\",dtype=\"float32\"))\n",
    "        #8x8x64\n",
    "        self.hw.append( tf.Variable(initializer(shape=(3,3,64,128),dtype=np.float32),name=\"hl3weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(128,dtype=np.float32),name=\"hl3bias\",dtype=\"float32\"))\n",
    "        #8x8x128\n",
    "        self.hw.append( tf.Variable(initializer(shape=(8*8*128,256),dtype=np.float32),name=\"hl4weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(256,dtype=np.float32),name=\"hl4bias\",dtype=\"float32\"))\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(256, n_classes),dtype=np.float32),name=\"outweigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(n_classes,dtype=np.float32),name=\"outbias\",dtype=\"float32\"))\n",
    "\n",
    "        self.trainable_variables = []\n",
    "        for i in range(len(self.hw)):\n",
    "            self.trainable_variables.append(self.hw[i])    \n",
    "            self.trainable_variables.append(self.hb[i])\n",
    "\n",
    "    def __call__(self,x): \n",
    "\n",
    "        out = tf.cast(x, tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 8, 8, 4])\n",
    "\n",
    "        layer=0\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "              #8*8*32\n",
    "        layer+=1\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "              #8*8*64\n",
    "        layer+=1  \n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*128\n",
    "        layer+=1\n",
    "        out =  tf.reshape(out,[-1, 8*8*128])\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "\n",
    "        layer+=1\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4829155, 64)\n",
      "(4829155,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "x_data = load_pkl(path+name_data)\n",
    "y_data = load_pkl(path+name_labels)[:,1] #Nota: pasa de onehot a logits\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size = test_percent, random_state = 0, shuffle = True)\n",
    "\n",
    "del x_data\n",
    "del y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if example==1:\n",
    "    model = Model_1()\n",
    "    encoding=encoding_1\n",
    "else:\n",
    "    model = Model_2()\n",
    "    encoding=encoding_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-25 15:10:56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 01/30 | time: 177s = 3.0m | train loss: 0.5441 | train acc: 0.7118 | test loss: 0.5158 | test acc: 0.7322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 02/30 | time: 172s = 2.9m | train loss: 0.5029 | train acc: 0.7411 | test loss: 0.4866 | test acc: 0.7521"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 03/30 | time: 175s = 2.9m | train loss: 0.4717 | train acc: 0.7619 | test loss: 0.4512 | test acc: 0.7755"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 04/30 | time: 174s = 2.9m | train loss: 0.4477 | train acc: 0.7774 | test loss: 0.4648 | test acc: 0.7591"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 05/30 | time: 174s = 2.9m | train loss: 0.4263 | train acc: 0.7916 | test loss: 0.4857 | test acc: 0.7505"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 06/30 | time: 175s = 2.9m | train loss: 0.4052 | train acc: 0.8059 | test loss: 0.4310 | test acc: 0.7881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 07/30 | time: 175s = 2.9m | train loss: 0.3827 | train acc: 0.8213 | test loss: 0.3929 | test acc: 0.8229"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 08/30 | time: 175s = 2.9m | train loss: 0.3581 | train acc: 0.8376 | test loss: 0.3797 | test acc: 0.8332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 09/30 | time: 175s = 2.9m | train loss: 0.3307 | train acc: 0.8544 | test loss: 0.3657 | test acc: 0.8388"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 10/30 | time: 176s = 2.9m | train loss: 0.3029 | train acc: 0.8700 | test loss: 0.3682 | test acc: 0.8523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 11/30 | time: 176s = 2.9m | train loss: 0.2749 | train acc: 0.8845 | test loss: 0.4109 | test acc: 0.8311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 12/30 | time: 176s = 2.9m | train loss: 0.2493 | train acc: 0.8972 | test loss: 0.3478 | test acc: 0.8668"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 13/30 | time: 176s = 2.9m | train loss: 0.2273 | train acc: 0.9074 | test loss: 0.3166 | test acc: 0.8810"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 14/30 | time: 176s = 2.9m | train loss: 0.2090 | train acc: 0.9159 | test loss: 0.3097 | test acc: 0.8837"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 15/30 | time: 175s = 2.9m | train loss: 0.1962 | train acc: 0.9220 | test loss: 0.2987 | test acc: 0.8887"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 16/30 | time: 176s = 2.9m | train loss: 0.1862 | train acc: 0.9264 | test loss: 0.3100 | test acc: 0.8877"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 17/30 | time: 178s = 3.0m | train loss: 0.1788 | train acc: 0.9299 | test loss: 0.3075 | test acc: 0.8915"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 18/30 | time: 178s = 3.0m | train loss: 0.1739 | train acc: 0.9325 | test loss: 0.3363 | test acc: 0.8875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 19/30 | time: 179s = 3.0m | train loss: 0.1692 | train acc: 0.9348 | test loss: 0.3307 | test acc: 0.8964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 20/30 | time: 179s = 3.0m | train loss: 0.1668 | train acc: 0.9362 | test loss: 0.3558 | test acc: 0.8796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 21/30 | time: 180s = 3.0m | train loss: 0.1645 | train acc: 0.9376 | test loss: 0.3285 | test acc: 0.8959"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 22/30 | time: 178s = 3.0m | train loss: 0.1634 | train acc: 0.9382 | test loss: 0.3283 | test acc: 0.8929"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 23/30 | time: 178s = 3.0m | train loss: 0.1609 | train acc: 0.9397 | test loss: 0.3314 | test acc: 0.8919"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 24/30 | time: 179s = 3.0m | train loss: 0.1607 | train acc: 0.9403 | test loss: 0.3693 | test acc: 0.8889"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 25/30 | time: 178s = 3.0m | train loss: 0.1593 | train acc: 0.9411 | test loss: 0.3394 | test acc: 0.8979"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 26/30 | time: 179s = 3.0m | train loss: 0.1591 | train acc: 0.9415 | test loss: 0.3643 | test acc: 0.8891"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 27/30 | time: 178s = 3.0m | train loss: 0.1595 | train acc: 0.9417 | test loss: 0.3773 | test acc: 0.8908"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 28/30 | time: 178s = 3.0m | train loss: 0.1606 | train acc: 0.9416 | test loss: 0.3749 | test acc: 0.8932"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 29/30 | time: 177s = 2.9m | train loss: 0.1595 | train acc: 0.9421 | test loss: 0.3665 | test acc: 0.8895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 30/30 | time: 176s = 2.9m | train loss: 0.1598 | train acc: 0.9423 | test loss: 0.3495 | test acc: 0.8922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitting(epochs=epochs,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        model=model,\n",
    "        optimizer=optim,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        loss_fn=loss_fn,\n",
    "        save_name=save_name,\n",
    "        encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitting(epochs=1,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        model= model, \n",
    "        load_name='tmp/tf_weights.0.6.h5',\n",
    "        save_name=save_name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
