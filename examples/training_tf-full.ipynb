{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chesslab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chesslab.utils import load_pkl\n",
    "from chesslab.training_tf import fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=1\n",
    "lr = 0.1\n",
    "epochs=5\n",
    "batch_size = 128\n",
    "test_percent=0.1\n",
    "\n",
    "path = 'D:/database/ccrl/'\n",
    "name_data='ccrl_states_full.pkl'\n",
    "name_labels='ccrl_results_full.pkl'\n",
    "save_name='./tmp/tf_weights-full.0'\n",
    "\n",
    "optim = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download=False\n",
    "if download:\n",
    "    from chesslab.utils import download_7z\n",
    "    path='./'\n",
    "    file_id = '1MFHFz_rxNziYSeN-9ruwnRiYskd0_9ss'\n",
    "    download_7z(file_id,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_1={\n",
    "    '.':np.array([ 0, 0, 0],dtype=np.float32),\n",
    "    'p':np.array([ 0, 0, 1],dtype=np.float32),\n",
    "    'P':np.array([ 0, 0,-1],dtype=np.float32),\n",
    "    'b':np.array([ 0, 1, 0],dtype=np.float32),\n",
    "    'B':np.array([ 0,-1, 0],dtype=np.float32),\n",
    "    'n':np.array([ 1, 0, 0],dtype=np.float32),\n",
    "    'N':np.array([-1, 0, 0],dtype=np.float32),\n",
    "    'r':np.array([ 0, 1, 1],dtype=np.float32),\n",
    "    'R':np.array([ 0,-1,-1],dtype=np.float32),\n",
    "    'q':np.array([ 1, 0, 1],dtype=np.float32),\n",
    "    'Q':np.array([-1, 0,-1],dtype=np.float32),\n",
    "    'k':np.array([ 1, 1, 0],dtype=np.float32),\n",
    "    'K':np.array([-1,-1, 0],dtype=np.float32)\n",
    "}\n",
    "\n",
    "encoding_2={\n",
    "    '.':np.array([0,0,0,0],dtype=np.float32),\n",
    "    'p':np.array([1,0,0,0],dtype=np.float32),\n",
    "    'P':np.array([0,0,0,1],dtype=np.float32),\n",
    "    'b':np.array([0,1,0,0],dtype=np.float32),\n",
    "    'B':np.array([0,0,1,0],dtype=np.float32),\n",
    "    'n':np.array([1,1,0,0],dtype=np.float32),\n",
    "    'N':np.array([0,0,1,1],dtype=np.float32),\n",
    "    'r':np.array([1,0,1,0],dtype=np.float32),\n",
    "    'R':np.array([0,1,0,1],dtype=np.float32),\n",
    "    'q':np.array([1,0,0,1],dtype=np.float32),\n",
    "    'Q':np.array([0,1,1,0],dtype=np.float32),\n",
    "    'k':np.array([1,1,1,0],dtype=np.float32),\n",
    "    'K':np.array([0,1,1,1],dtype=np.float32)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1():\n",
    "\n",
    "    def __init__(self,\n",
    "                   n_classes=2):\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "        self.hw=[]\n",
    "        self.hb=[]\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(7,7,3,32),dtype=np.float32),name=\"hl1weigths\",dtype=\"float32\") )\n",
    "        self.hb.append( tf.Variable(np.zeros(32,dtype=np.float32),name=\"hl1bias\",dtype=\"float32\") )\n",
    "        #8x8x32\n",
    "        self.hw.append( tf.Variable(initializer(shape=(5,5,32,64),dtype=np.float32),name=\"hl2weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(64,dtype=np.float32),name=\"hl2bias\",dtype=\"float32\"))\n",
    "        #8x8x64\n",
    "        self.hw.append( tf.Variable(initializer(shape=(3,3,64,128),dtype=np.float32),name=\"hl3weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(128,dtype=np.float32),name=\"hl3bias\",dtype=\"float32\"))\n",
    "        #8x8x128\n",
    "        self.hw.append( tf.Variable(initializer(shape=(8*8*128,256),dtype=np.float32),name=\"hl4weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(256,dtype=np.float32),name=\"hl4bias\",dtype=\"float32\"))\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(256, n_classes),dtype=np.float32),name=\"outweigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(n_classes,dtype=np.float32),name=\"outbias\",dtype=\"float32\"))\n",
    "\n",
    "        self.trainable_variables = []\n",
    "        for i in range(len(self.hw)):\n",
    "            self.trainable_variables.append(self.hw[i])    \n",
    "            self.trainable_variables.append(self.hb[i])\n",
    "\n",
    "    def __call__(self,x): \n",
    "\n",
    "        # Declarando la arquitectura\n",
    "        out = tf.cast(x, tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 8, 8, 3])\n",
    "\n",
    "        layer=0\n",
    "        out = tf.add(out, 1e-8)\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*32\n",
    "        layer+=1\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*64\n",
    "        layer+=1  \n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*128\n",
    "        layer+=1\n",
    "        out =  tf.reshape(out,[-1, 8*8*128])\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "\n",
    "        layer+=1\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Model_2():\n",
    "\n",
    "    def __init__(self,\n",
    "                   n_classes=2):\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "        self.hw=[]\n",
    "        self.hb=[]\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(7,7,4,32),dtype=np.float32),name=\"hl1weigths\",dtype=\"float32\") )\n",
    "        self.hb.append( tf.Variable(np.zeros(32,dtype=np.float32),name=\"hl1bias\",dtype=\"float32\") )\n",
    "        #8x8x32\n",
    "        self.hw.append( tf.Variable(initializer(shape=(5,5,32,64),dtype=np.float32),name=\"hl2weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(64,dtype=np.float32),name=\"hl2bias\",dtype=\"float32\"))\n",
    "        #8x8x64\n",
    "        self.hw.append( tf.Variable(initializer(shape=(3,3,64,128),dtype=np.float32),name=\"hl3weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(128,dtype=np.float32),name=\"hl3bias\",dtype=\"float32\"))\n",
    "        #8x8x128\n",
    "        self.hw.append( tf.Variable(initializer(shape=(8*8*128,256),dtype=np.float32),name=\"hl4weigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(256,dtype=np.float32),name=\"hl4bias\",dtype=\"float32\"))\n",
    "\n",
    "        self.hw.append( tf.Variable(initializer(shape=(256, n_classes),dtype=np.float32),name=\"outweigths\",dtype=\"float32\"))\n",
    "        self.hb.append( tf.Variable(np.zeros(n_classes,dtype=np.float32),name=\"outbias\",dtype=\"float32\"))\n",
    "\n",
    "        self.trainable_variables = []\n",
    "        for i in range(len(self.hw)):\n",
    "            self.trainable_variables.append(self.hw[i])    \n",
    "            self.trainable_variables.append(self.hb[i])\n",
    "\n",
    "    def __call__(self,x): \n",
    "\n",
    "        out = tf.cast(x, tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 8, 8, 4])\n",
    "\n",
    "        layer=0\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "              #8*8*32\n",
    "        layer+=1\n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "              #8*8*64\n",
    "        layer+=1  \n",
    "        out = tf.nn.conv2d(out,self.hw[layer], strides=[1,1,1,1], padding='SAME')  \n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.elu(out)\n",
    "              #8*8*128\n",
    "        layer+=1\n",
    "        out =  tf.reshape(out,[-1, 8*8*128])\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "        out = tf.nn.relu(out)\n",
    "\n",
    "        layer+=1\n",
    "        out =  tf.matmul(out,self.hw[layer])\n",
    "        out = tf.add(out, self.hb[layer])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17164805, 64)\n",
      "(17164805,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "x_data = load_pkl(path+name_data)\n",
    "y_data = load_pkl(path+name_labels)[:,1] #Nota: pasa de onehot a logits\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size = test_percent, random_state = 0, shuffle = True)\n",
    "\n",
    "del x_data\n",
    "del y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if example==1:\n",
    "    model = Model_1()\n",
    "    encoding=encoding_1\n",
    "else:\n",
    "    model = Model_2()\n",
    "    encoding=encoding_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "num_parallel_calls must be greater than zero. [Op:ParallelMapDatasetV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9860/2857537280.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m fitting(epochs=epochs,\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daniel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\chesslab\\training_tf.py\u001b[0m in \u001b[0;36mfitting\u001b[1;34m(start, epochs, x_train, y_train, x_test, y_test, model, optimizer, batch_size, lr, loss_fn, save_name, encoding, load_name, shuffle_train, shuffle_test, download_models, num_workers)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mtrain_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daniel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\chesslab\\training_tf.py\u001b[0m in \u001b[0;36mdata_loader\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mwrapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daniel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[0;32m   1925\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1927\u001b[1;33m       return ParallelMapDataset(\n\u001b[0m\u001b[0;32m   1928\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1929\u001b[0m           \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daniel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   4534\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[0;32m   4535\u001b[0m         num_parallel_calls, dtype=dtypes.int64, name=\"num_parallel_calls\")\n\u001b[1;32m-> 4536\u001b[1;33m     variant_tensor = gen_dataset_ops.parallel_map_dataset_v2(\n\u001b[0m\u001b[0;32m   4537\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4538\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daniel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mparallel_map_dataset_v2\u001b[1;34m(input_dataset, other_arguments, num_parallel_calls, f, output_types, output_shapes, use_inter_op_parallelism, deterministic, preserve_cardinality, name)\u001b[0m\n\u001b[0;32m   5506\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5507\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5508\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5509\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5510\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daniel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6896\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6897\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6898\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daniel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: num_parallel_calls must be greater than zero. [Op:ParallelMapDatasetV2]"
     ]
    }
   ],
   "source": [
    "fitting(epochs=epochs,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        model=model,\n",
    "        optimizer=optim,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        loss_fn=loss_fn,\n",
    "        save_name=save_name,\n",
    "        encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitting(epochs=1,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        model= model, \n",
    "        load_name='tmp/tf_weights.0.6.h5',\n",
    "        save_name=save_name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
